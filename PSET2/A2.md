### 1. Take `building.jpg`

   **a.** Use a simple filter like sobel to detect edge pixels. You can use opencv  (5pts)

   **b.** Write  non-maximum suppression code to thin out edges. You can not use opencv, you can use numpy (10pts)

   **c.** Use these edge pixels to mark out one of the floor on the building-- that is there should be an edge line in your image along one of the floors (most probably the window line) -- for this I want to see what are the assumptions you are making re the line you are detecting. Also stick to Least Square method of line fitting. Play with NMS (b above). Provide code, no opencv. (15 pts) 

### 2. Implement a SIFT key point detector from scratch in python. For an image, (any image), compare your implementation with openCV implementation (with same parameters). If your code is not 95%-105% as efficient (compare run times) and not >75% accurate (precision/recall) as opencv, you will get a zero on this question. UNLESS you can find the exact reasons -- meaning pinpoint exact reasons -- for it not being as good as opencv. For example you can prove that opencv convolution is faster than your/numpy convolution (this is not true; its just and example of pinpoint reason). (25 pts) Use Shrek images to test above out.  
Stick to the key point detector algorithm for now, not the feature description part. 

### 3. Take selfies and do key point detection using above code. Describe the results you see. You should try multiple angles. (5 pts)